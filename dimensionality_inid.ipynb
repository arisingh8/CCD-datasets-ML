{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed170f67-69f0-4285-a620-42605baf43be",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'LinearDiscriminantAnalysis' from 'sklearn.linear_model' (/home/ari/mambaforge/envs/ccd/lib/python3.10/site-packages/sklearn/linear_model/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 14\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseEstimator, TransformerMixin, clone\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpyswarms\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mps\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinear_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LinearDiscriminantAnalysis\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mxgboost\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mxgb\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mxgboost\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m XGBClassifier\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'LinearDiscriminantAnalysis' from 'sklearn.linear_model' (/home/ari/mambaforge/envs/ccd/lib/python3.10/site-packages/sklearn/linear_model/__init__.py)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, clone\n",
    "import pyswarms as ps\n",
    "from sklearn.linear_model import LinearDiscriminantAnalysis\n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c2daa1-a846-4bf0-876a-b8fbc346c9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PSOTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        \n",
    "        # Define objective function\n",
    "        def f_per_particle(m, alpha):\n",
    "            \"\"\"Computes for the objective function per particle\n",
    "\n",
    "            Inputs\n",
    "            ------\n",
    "            m : numpy.ndarray\n",
    "                Binary mask that can be obtained from BinaryPSO, will\n",
    "                be used to mask features.\n",
    "            alpha: float (default is 0.5)\n",
    "                Constant weight for trading-off classifier performance\n",
    "                and number of features\n",
    "\n",
    "            Returns\n",
    "            -------\n",
    "            numpy.ndarray\n",
    "                Computed objective function\n",
    "            \"\"\"\n",
    "            total_features = X.shape[1]\n",
    "            # Get the subset of the features from the binary mask\n",
    "            if np.count_nonzero(m) == 0:\n",
    "                X_subset = X\n",
    "            else:\n",
    "                X_subset = X[:,m==1]\n",
    "            # Perform classification and store performance in P\n",
    "            self.model.fit(X_subset, y)\n",
    "            P = (self.model.predict(X_subset) == y).mean()\n",
    "            # Compute for the objective function\n",
    "            j = (alpha * (1.0 - P)\n",
    "                + (1.0 - alpha) * (1 - (X_subset.shape[1] / total_features)))\n",
    "\n",
    "            return j\n",
    "        \n",
    "        def f(x, alpha=0.88):\n",
    "            \"\"\"Higher-level method to do classification in the\n",
    "            whole swarm.\n",
    "\n",
    "            Inputs\n",
    "            ------\n",
    "            x: numpy.ndarray of shape (n_particles, dimensions)\n",
    "                The swarm that will perform the search\n",
    "\n",
    "            Returns\n",
    "            -------\n",
    "            numpy.ndarray of shape (n_particles, )\n",
    "                The computed loss for each particle\n",
    "            \"\"\"\n",
    "            n_particles = x.shape[0]\n",
    "            j = [f_per_particle(x[i], alpha) for i in range(n_particles)]\n",
    "            return np.array(j)\n",
    "        \n",
    "        # Initialize swarm, arbitrary\n",
    "        options = {'c1': 0.5, 'c2': 0.5, 'w':0.9, 'k': 30, 'p':2}\n",
    "\n",
    "        # Call instance of PSO\n",
    "        dimensions = X.shape[1] # dimensions should be the number of features\n",
    "        optimizer = ps.discrete.BinaryPSO(n_particles=30, \n",
    "                                          dimensions=dimensions, \n",
    "                                          options=options)\n",
    "\n",
    "        # Perform optimization\n",
    "        cost, pos = optimizer.optimize(f, \n",
    "                                       iters=1000, \n",
    "                                       verbose=2)\n",
    "        self.positions = pos\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        X_selected_features = X[:, pos==1]\n",
    "        return X_selected_features\n",
    "    \n",
    "    def get_params(self, deep=True):\n",
    "        return {\"model\": self.model}\n",
    "    \n",
    "    def set_params(self, **parameters):\n",
    "        for parameter, value in parameters.items():\n",
    "            setattr(self, parameter, value)\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa87051-160b-4fda-b092-f3c8db1b8487",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/merged_and_edited_dataset.csv\",\n",
    "                dtype={\n",
    "                        \"src_ip\": \"string\",\n",
    "                        \"dst_ip\": \"string\",\n",
    "                        \"client_fingerprint\": \"string\",\n",
    "                        \"application_name\": \"string\",\n",
    "                        \"application_category_name\": \"string\",\n",
    "                        \"requested_server_name\": \"string\",\n",
    "                        \"atk_type\": \"string\",\n",
    "                        \"traffic_type\": \"string\"\n",
    "                    }).drop([\n",
    "                        \"Unnamed: 0\",\n",
    "                        \"server_fingerprint\",\n",
    "                        \"user_agent\",\n",
    "                        \"content_type\", \n",
    "                        \"src_ip\", \n",
    "                        \"dst_ip\", \n",
    "                        \"splt_direction\", \n",
    "                        \"splt_ps\", \n",
    "                        \"splt_piat_ms\", \n",
    "                        \"application_name\", \n",
    "                        \"application_category_name\", \n",
    "                        \"requested_server_name\", \n",
    "                        \"client_fingerprint\"\n",
    "                    ], axis=1)\n",
    "X = df.drop(['id', 'traffic_type', 'atk_type'], axis=1)\n",
    "y = LabelEncoder().fit_transform(df['atk_type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd904a2-7ebe-47ea-976d-f4883244a554",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "classifier = XGBClassifier(n_estimators = 500,\n",
    "                           max_depth = 7,\n",
    "                           learning_rate = 0.1,\n",
    "                           verbose=None,\n",
    "                           eval_metric='logloss', \n",
    "                           tree_method=\"gpu_hist\")\n",
    "scaler = StandardScaler()\n",
    "pipe = Pipeline(\n",
    "    [\n",
    "        (\"scaling\", scaler),\n",
    "        (\"fs\", \"passthrough\"),\n",
    "        (\"classify\", classifier)\n",
    "    ],\n",
    "    memory = \"cache/\"\n",
    ")\n",
    "\n",
    "param_grid = [\n",
    "    {\n",
    "        \"fs\": [PSOTransformer(LinearDiscriminantAnalysis())]\n",
    "    }\n",
    "    #{\n",
    "    #    \"fs\": [PCA()],\n",
    "    #    \"fs__n_components\": np.arange(5, len(X.columns), 10)\n",
    "    #}\n",
    "]\n",
    "\n",
    "search = GridSearchCV(pipe, param_grid, cv=5, verbose=4)\n",
    "search.fit(X, y)\n",
    "print(\"Best parameter (CV score=%0.3f):\" % search.best_score_)\n",
    "print(search.best_params_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ccd]",
   "language": "python",
   "name": "conda-env-ccd-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
