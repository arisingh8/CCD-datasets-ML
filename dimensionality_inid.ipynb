{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed170f67-69f0-4285-a620-42605baf43be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, clone\n",
    "import pyswarms as ps\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import random\n",
    "from deap import base, creator, tools, algorithms\n",
    "from operator import attrgetter\n",
    "\n",
    "import multiprocessing\n",
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c2daa1-a846-4bf0-876a-b8fbc346c9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PSOTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        \n",
    "        # Define objective function\n",
    "        def f_per_particle(m, alpha):\n",
    "            \"\"\"Computes for the objective function per particle\n",
    "\n",
    "            Inputs\n",
    "            ------\n",
    "            m : numpy.ndarray\n",
    "                Binary mask that can be obtained from BinaryPSO, will\n",
    "                be used to mask features.\n",
    "            alpha: float (default is 0.5)\n",
    "                Constant weight for trading-off classifier performance\n",
    "                and number of features\n",
    "\n",
    "            Returns\n",
    "            -------\n",
    "            numpy.ndarray\n",
    "                Computed objective function\n",
    "            \"\"\"\n",
    "            total_features = X.shape[1]\n",
    "            # Get the subset of the features from the binary mask\n",
    "            if np.count_nonzero(m) == 0:\n",
    "                X_subset = X\n",
    "            else:\n",
    "                X_subset = X[:,m==1]\n",
    "            # Perform classification and store performance in P\n",
    "            self.model.fit(X_subset, y)\n",
    "            P = (self.model.predict(X_subset) == y).mean()\n",
    "            # Compute for the objective function\n",
    "            j = (alpha * (1.0 - P)\n",
    "                + (1.0 - alpha) * (1 - (X_subset.shape[1] / total_features)))\n",
    "\n",
    "            return j\n",
    "        \n",
    "        def f(x, alpha=0.88):\n",
    "            \"\"\"Higher-level method to do classification in the\n",
    "            whole swarm.\n",
    "\n",
    "            Inputs\n",
    "            ------\n",
    "            x: numpy.ndarray of shape (n_particles, dimensions)\n",
    "                The swarm that will perform the search\n",
    "\n",
    "            Returns\n",
    "            -------\n",
    "            numpy.ndarray of shape (n_particles, )\n",
    "                The computed loss for each particle\n",
    "            \"\"\"\n",
    "            n_particles = x.shape[0]\n",
    "            j = Parallel(n_jobs=4)(\n",
    "                delayed(f_per_particle)(x[i], alpha) for i in range(n_particles))\n",
    "            return np.array(j)\n",
    "        \n",
    "        # Initialize swarm, arbitrary\n",
    "        options = {'c1': 0.5, 'c2': 0.5, 'w':0.9, 'k': 30, 'p':2}\n",
    "\n",
    "        # Call instance of PSO\n",
    "        dimensions = X.shape[1] # dimensions should be the number of features\n",
    "        optimizer = ps.discrete.BinaryPSO(n_particles=30, \n",
    "                                          dimensions=dimensions, \n",
    "                                          options=options)\n",
    "\n",
    "        # Perform optimization\n",
    "        cost, pos = optimizer.optimize(f, \n",
    "                                       iters=1000, \n",
    "                                       verbose=2)\n",
    "        self.positions = pos\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        return X[:, self.positions==1]\n",
    "    \n",
    "    def get_feature_names_out(self, input_features=None):\n",
    "        return [name for name, selected in zip(input_features, self.positions) if selected == 1]\n",
    "    \n",
    "    def get_params(self, deep=True):\n",
    "        return {\"model\": self.model}\n",
    "    \n",
    "    def set_params(self, **parameters):\n",
    "        for parameter, value in parameters.items():\n",
    "            setattr(self, parameter, value)\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa87051-160b-4fda-b092-f3c8db1b8487",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/merged_and_edited_dataset.csv\",\n",
    "                dtype={\n",
    "                        \"src_ip\": \"string\",\n",
    "                        \"dst_ip\": \"string\",\n",
    "                        \"client_fingerprint\": \"string\",\n",
    "                        \"application_name\": \"string\",\n",
    "                        \"application_category_name\": \"string\",\n",
    "                        \"requested_server_name\": \"string\",\n",
    "                        \"atk_type\": \"string\",\n",
    "                        \"traffic_type\": \"string\"\n",
    "                    }).drop([\n",
    "                        \"Unnamed: 0\",\n",
    "                        \"server_fingerprint\",\n",
    "                        \"user_agent\",\n",
    "                        \"content_type\", \n",
    "                        \"src_ip\", \n",
    "                        \"dst_ip\", \n",
    "                        \"splt_direction\", \n",
    "                        \"splt_ps\", \n",
    "                        \"splt_piat_ms\", \n",
    "                        \"application_name\", \n",
    "                        \"application_category_name\", \n",
    "                        \"requested_server_name\", \n",
    "                        \"client_fingerprint\"\n",
    "                    ], axis=1)\n",
    "X = df.drop(['id', 'traffic_type', 'atk_type'], axis=1)\n",
    "y = LabelEncoder().fit_transform(df['atk_type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b2366b-fd54-4016-8d0c-508e65dae6f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureSetChromosome(object):\n",
    "    def __init__(self, genes, size):\n",
    "        self.genes = np.random.choice(genes, size)\n",
    "    \n",
    "    def get_genes(self):\n",
    "        return self.genes\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.genes)\n",
    "    \n",
    "    def __iter__(self):\n",
    "        yield from self.genes\n",
    "    \n",
    "    def __getitem__(self, key):\n",
    "        return self.genes[key]\n",
    "    \n",
    "    def __setitem__(self, key, data):\n",
    "        self.genes[key] = data\n",
    "\n",
    "# setting individual creator\n",
    "creator.create('FitnessMax', base.Fitness, weights=(1,))\n",
    "creator.create('Individual', FeatureSetChromosome, fitness=creator.FitnessMax)\n",
    "\n",
    "def mutate(individual, pb=0):\n",
    "    # maximal amount of mutated genes\n",
    "    n_mutated_max = max(1, int(len(individual) * pb))\n",
    "    # generate the random amount of mutated genes\n",
    "    n_mutated = random.randint(1, n_mutated_max)\n",
    "    # select random genes which need to be mutated\n",
    "    mutated_indexes = random.sample(\n",
    "        [index for index in range(len(individual))], n_mutated)\n",
    "    # mutation\n",
    "    for index in mutated_indexes:\n",
    "        individual[index] = 0 if individual[index] else 1 # flip between 0s and 1s\n",
    "    return individual,\n",
    "\n",
    "def select_best(individuals, k, fit_attr='fitness'):\n",
    "    return sorted(set(individuals), key=attrgetter(fit_attr))[:k]\n",
    "\n",
    "def evaluate(individual, model, X, y, n_splits=3):\n",
    "    acc_folds = cross_val_score(\n",
    "        model, \n",
    "        X[:, individual.get_genes()==1], \n",
    "        y, \n",
    "        cv=n_splits,\n",
    "        scoring='accuracy')\n",
    "    return acc_folds.mean(),\n",
    "\n",
    "class GATransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, model):   \n",
    "        self.model = model\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        def init_individual(ind_class, genes=None, size=None):\n",
    "            return ind_class(genes, size)\n",
    "        \n",
    "        toolbox = base.Toolbox()\n",
    "        \n",
    "        n_features = X.shape[1]\n",
    "        toolbox.register(\n",
    "            'individual', init_individual, creator.Individual,\n",
    "            genes=[0, 1], size=n_features)\n",
    "        toolbox.register(\n",
    "            'population', tools.initRepeat, list, toolbox.individual)\n",
    "\n",
    "        # raise population\n",
    "        self.pop = toolbox.population(50)\n",
    "\n",
    "        toolbox.register('mate', tools.cxTwoPoint)\n",
    "        toolbox.register('mutate', mutate, pb=0.2)\n",
    "        toolbox.register('evaluate', evaluate, model=self.model, X=X, y=y, n_splits=3)\n",
    "        toolbox.register('select', select_best)\n",
    "        \n",
    "        pool = multiprocessing.Pool()\n",
    "        toolbox.register(\"map\", pool.map)\n",
    "        \n",
    "        hof = tools.HallOfFame(5)\n",
    "        algorithms.eaMuPlusLambda(\n",
    "            self.pop, toolbox,\n",
    "            mu=10, lambda_=30, cxpb=0.2, mutpb=0.8,\n",
    "            ngen=20, halloffame=hof, verbose=True)\n",
    "        \n",
    "        self.feature_list = hof[0].get_genes()\n",
    "        print(self.feature_list)\n",
    "        \n",
    "        return self\n",
    "        \n",
    "    def transform(self, X, y=None):\n",
    "        return X[:, self.feature_list==1]\n",
    "    \n",
    "    def get_feature_names_out(self, input_features=None):\n",
    "        return [name for name, selected in zip(input_features, self.feature_list) if selected == 1]\n",
    "    \n",
    "    def get_params(self, deep=True):\n",
    "        return {\"model\": self.model}\n",
    "    \n",
    "    def set_params(self, **parameters):\n",
    "        for parameter, value in parameters.items():\n",
    "            setattr(self, parameter, value)\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd904a2-7ebe-47ea-976d-f4883244a554",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "classifier = XGBClassifier(n_estimators = 500,\n",
    "                           max_depth = 7,\n",
    "                           learning_rate = 0.1,\n",
    "                           verbose=None,\n",
    "                           eval_metric='logloss')\n",
    "scaler = StandardScaler()\n",
    "pipe = Pipeline(\n",
    "    [\n",
    "        (\"scaling\", scaler),\n",
    "        (\"fs\", \"passthrough\"),\n",
    "        (\"classify\", classifier)\n",
    "    ],\n",
    "    memory = \"cache/\"\n",
    ")\n",
    "\n",
    "param_grid = [\n",
    "    {\n",
    "        \"fs\": [GATransformer(model=SGDClassifier(loss=\"log_loss\")), \n",
    "               PSOTransformer(model=SGDClassifier(loss=\"log_loss\"))]\n",
    "    }\n",
    "]\n",
    "\n",
    "search = GridSearchCV(pipe, param_grid, cv=3, verbose=4)\n",
    "search.fit(X, y)\n",
    "print(\"Best parameter (CV score=%0.3f):\" % search.best_score_)\n",
    "print(search.best_params_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ccd]",
   "language": "python",
   "name": "conda-env-ccd-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
