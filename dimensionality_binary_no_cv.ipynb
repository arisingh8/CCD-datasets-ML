{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearnex import patch_sklearn\n",
    "patch_sklearn()\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, clone\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, roc_auc_score\n",
    "\n",
    "import random\n",
    "from deap import base, creator, tools, algorithms\n",
    "\n",
    "from cuml.svm import LinearSVC as cuSVC\n",
    "from cuml import LogisticRegression as cuLR\n",
    "from cuml.neighbors import KNeighborsClassifier as cuKNN\n",
    "from cuml.ensemble import RandomForestClassifier as cuRF\n",
    "from cuml.naive_bayes import GaussianNB as cuNB\n",
    "from sklearn.naive_bayes import GaussianNB as skNB\n",
    "from sklearn.ensemble import RandomForestClassifier as skRF\n",
    "from sklearn.neighbors import KNeighborsClassifier as skKNN\n",
    "from sklearn.svm import LinearSVC as skSVC\n",
    "from sklearn.linear_model import LogisticRegression as skLR\n",
    "\n",
    "import shap\n",
    "\n",
    "from joblib import Parallel, delayed, load, dump\n",
    "\n",
    "from collections import defaultdict\n",
    "import time\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting individual creator\n",
    "creator.create('FitnessMulti', base.Fitness, weights=(1, -1))\n",
    "creator.create('Individual', list, fitness=creator.FitnessMulti)\n",
    "\n",
    "def has_converged(series, w, eps):\n",
    "    if w >= len(series):\n",
    "        return False\n",
    "\n",
    "    current = series[len(series)-1]\n",
    "    window = series[-w-1:-1]\n",
    "    average_error = np.mean(np.abs(window-current)/np.abs(current))\n",
    "    return average_error <= eps\n",
    "\n",
    "def evaluate(individual, model, X, y, gamma, r_eps, r_w, s_eps, s_w):\n",
    "    n = len(X)\n",
    "    b = round(n**gamma)\n",
    "    subset_scores = []\n",
    "    while not has_converged(subset_scores, s_w, s_eps):\n",
    "        subsample_idx = random.sample(range(n), b)\n",
    "        X_sampled = X[subsample_idx, :][:, individual]\n",
    "        y_sampled = y[subsample_idx]\n",
    "        train, test = train_test_split(np.arange(b), test_size=0.33, stratify=y_sampled, random_state=42)\n",
    "        monte_carlo_scores = []\n",
    "        while not has_converged(monte_carlo_scores, r_w, r_eps):\n",
    "            sample_weights = np.random.multinomial(n=n, pvals=[1/b]*b, size=1)[0]\n",
    "            clf = clone(model)\n",
    "            clf.fit(X=X_sampled[train, :], \n",
    "                    y=y_sampled[train], \n",
    "                    sample_weight=sample_weights[train])\n",
    "            monte_carlo_scores.append(\n",
    "                roc_auc_score(y_sampled[test], \n",
    "                       clf.predict_proba(X_sampled[test, :])[:, 1],\n",
    "                       sample_weight=sample_weights[test])\n",
    "            )\n",
    "        subset_scores.append(np.mean(monte_carlo_scores))\n",
    "    return np.mean(subset_scores), np.count_nonzero(individual)\n",
    "\n",
    "class GATransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, model):   \n",
    "        self.model = model\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        # memmapping for later\n",
    "        X_path = \"cache/X_memmap.mmap\"\n",
    "        if os.path.exists(X_path): os.unlink(X_path)\n",
    "        y_path = \"cache/y_memmap.mmap\"\n",
    "        if os.path.exists(y_path): os.unlink(y_path)\n",
    "        dump(X, X_path)\n",
    "        dump(y, y_path)\n",
    "\n",
    "        del X, y\n",
    "        gc.collect()\n",
    "\n",
    "        X_memmap = load(X_path, mmap_mode=\"r+\")\n",
    "        y_memmap = load(y_path, mmap_mode=\"r+\")\n",
    "\n",
    "        toolbox = base.Toolbox()\n",
    "        \n",
    "        n_features = X_memmap.shape[1]\n",
    "        toolbox.register('attr_bool', random.choice, [True, False])\n",
    "        toolbox.register(\n",
    "            'individual', tools.initRepeat, creator.Individual,\n",
    "            toolbox.attr_bool, n=n_features)\n",
    "        toolbox.register(\n",
    "            'population', tools.initRepeat, list, toolbox.individual)\n",
    "\n",
    "        # raise population\n",
    "        pop = toolbox.population(10)\n",
    "\n",
    "        toolbox.register('mate', tools.cxTwoPoint)\n",
    "        toolbox.register('mutate', tools.mutFlipBit, indpb=0.2)\n",
    "        toolbox.register('evaluate', evaluate, model=self.model, \n",
    "                         gamma=0.7, r_eps = 0.04, r_w = 20, s_eps = 0.025, s_w = 5)\n",
    "        toolbox.register('select', tools.selNSGA2)\n",
    "        \n",
    "        perf_stats = tools.Statistics(key=lambda ind: ind.fitness.values[0])\n",
    "        n_feat_stats = tools.Statistics(key=lambda ind: ind.fitness.values[1])\n",
    "        mstats = tools.MultiStatistics(perf=perf_stats, n_features=n_feat_stats)\n",
    "        mstats.register(\"mean\", np.mean)\n",
    "        mstats.register(\"max\", max)\n",
    "        mstats.register(\"min\", min)\n",
    "\n",
    "        hof = tools.HallOfFame(3)\n",
    "\n",
    "        mu = 10\n",
    "        lambda_ = 20\n",
    "        cxpb = 0.5\n",
    "        mutpb = 0.5\n",
    "        ngen = 40\n",
    "\n",
    "        logbook = tools.Logbook()\n",
    "        logbook.header = ['gen', 'nevals'] + mstats.fields\n",
    "\n",
    "        # Evaluate the individuals with an invalid fitness\n",
    "        invalid_ind = [ind for ind in pop if not ind.fitness.valid]\n",
    "        fitnesses = Parallel(n_jobs=6, max_nbytes=None)(\n",
    "            delayed(toolbox.evaluate)(list(ind), X=X_memmap, y=y_memmap) for ind in invalid_ind\n",
    "        )\n",
    "        for ind, fit in zip(invalid_ind, fitnesses):\n",
    "            ind.fitness.values = fit\n",
    "        \n",
    "        hof.update(pop)\n",
    "\n",
    "        # no real selecting, only to assign crowding distance\n",
    "        pop = toolbox.select(pop, len(pop))\n",
    "\n",
    "        record = mstats.compile(pop)\n",
    "        logbook.record(gen=0, nevals=len(invalid_ind), **record)\n",
    "        print(logbook.stream)\n",
    "\n",
    "        with Parallel(n_jobs=6, max_nbytes=None) as parallel:\n",
    "            for gen in range(1, ngen+1):\n",
    "                offspring = algorithms.varOr(pop, toolbox, lambda_, cxpb, mutpb)\n",
    "\n",
    "                # Evaluate the individuals with an invalid fitness\n",
    "                invalid_ind = [ind for ind in offspring if not ind.fitness.valid]\n",
    "                fitnesses = parallel(delayed(toolbox.evaluate)\n",
    "                                     (list(ind), X=X_memmap, y=y_memmap) for ind in invalid_ind)\n",
    "                for ind, fit in zip(invalid_ind, fitnesses):\n",
    "                    ind.fitness.values = fit\n",
    "                \n",
    "                hof.update(pop)\n",
    "\n",
    "                # Select the next generation population\n",
    "                pop[:] = toolbox.select(pop + offspring, mu)\n",
    "\n",
    "                record = mstats.compile(pop)\n",
    "                logbook.record(gen=gen, nevals=len(invalid_ind), **record)\n",
    "                print(logbook.stream)\n",
    "        \n",
    "        self.logbook = logbook\n",
    "\n",
    "        fig, ax1 = plt.subplots()\n",
    "\n",
    "        ax1.set_xlabel('Number of generations')\n",
    "        ax1.set_ylabel('Performance')\n",
    "        ax1.plot(logbook.chapters['perf'].select(\"gen\"), logbook.chapters['perf'].select(\"max\"), label=\"Max perf\")\n",
    "\n",
    "        ax2 = ax1.twinx()\n",
    "        ax2.set_ylabel('Number of features')\n",
    "        ax2.plot(logbook.chapters['n_features'].select(\"gen\"), logbook.chapters['n_features'].select(\"min\"), label=\"Min features\")\n",
    "\n",
    "        fig.suptitle(f'GA Transformer Evolution: {type(self.model).__name__}')\n",
    "        fig.legend()\n",
    "        fig.tight_layout()\n",
    "        \n",
    "        plt.show()\n",
    "        \n",
    "        self.best_features = hof[0]\n",
    "        return self\n",
    "    \n",
    "    def get_feature_names_out(self, input_features=None):\n",
    "        if input_features is not None:\n",
    "            return [name for name, selected in zip(input_features, self.best_features) if selected]\n",
    "        else:\n",
    "            return [name for name, selected in zip(self.feature_names_in_, self.best_features) if selected]\n",
    "        \n",
    "    def transform(self, X, y=None):\n",
    "        return X[:, self.best_features]\n",
    "    \n",
    "    def get_logbook(self):\n",
    "        return self.logbook\n",
    "    \n",
    "    def get_params(self, deep=True):\n",
    "        return {\"model\": self.model}\n",
    "    \n",
    "    def set_params(self, **parameters):\n",
    "        for parameter, value in parameters.items():\n",
    "            setattr(self, parameter, value)\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_parquet(\"data/CCD-INIDv1/binary_train.parquet\")\n",
    "X_train = train_df.drop(['traffic_type'], axis=1)\n",
    "y_train = LabelEncoder().fit_transform(train_df['traffic_type'])\n",
    "print(f\"X_train shape is {X_train.shape}\")\n",
    "del train_df\n",
    "\n",
    "test_df = pd.read_parquet(\"data/CCD-INIDv1/binary_test.parquet\")\n",
    "X_test = test_df.drop(['traffic_type'], axis=1)\n",
    "y_test = LabelEncoder().fit_transform(test_df['traffic_type'])\n",
    "print(f\"X_test shape is {X_test.shape}\")\n",
    "del test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_scorer(clf, X, y):\n",
    "    y_pred = clf.predict(X)\n",
    "    precision, recall, f1_score, support = precision_recall_fscore_support(y, y_pred, average=None, zero_division=1)\n",
    "    return {\n",
    "        \"accuracy\": accuracy_score(y, y_pred),\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1_score\": f1_score,\n",
    "        \"support\": support,\n",
    "        \"roc_auc_score\": roc_auc_score(y, clf.predict_proba(X)[:, 1])\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [skNB(), \n",
    "          cuRF(n_estimators = 500),\n",
    "          cuLR(max_iter=5000),\n",
    "          cuSVC(probability=True),\n",
    "          cuKNN(n_neighbors=17)]\n",
    "results = defaultdict(list)\n",
    "\n",
    "print(\"fitting GA now\")\n",
    "start = time.time()\n",
    "transform_pipe = make_pipeline(StandardScaler(), GATransformer(model=skNB()))\n",
    "transform_pipe.fit(X_train, y_train)\n",
    "end = time.time()\n",
    "print(f\"Took {end - start} seconds to fit GA\")\n",
    "\n",
    "results['logbook'] = transform_pipe['gatransformer'].get_logbook()\n",
    "\n",
    "X_train_selected = transform_pipe.transform(X_train)\n",
    "X_test_selected = transform_pipe.transform(X_test)\n",
    "\n",
    "print(\"fitting models with FS now\")\n",
    "\n",
    "for model in models:\n",
    "    print(\"-------------------------------\")\n",
    "    print(f\"Starting fit with GA selection for {model}\")\n",
    "    print(\"-------------------------------\")\n",
    "    start = time.time()\n",
    "    clf = clone(model)\n",
    "    clf.fit(X_train_selected, y_train)\n",
    "    scores = custom_scorer(clf, X_test_selected, y_test)\n",
    "    end = time.time()\n",
    "    scores['model'] = type(model).__name__\n",
    "    scores['n_features'] = X_train_selected.shape[1]\n",
    "    scores['time'] = end - start\n",
    "    print(\"-------------------------------\")\n",
    "    print(f\"Results for {model} with GA selection: \")\n",
    "    print(scores)\n",
    "    print(f\"Took {end - start} seconds\")\n",
    "    print(\"-------------------------------\")\n",
    "    results['fs_scores'].append(scores)\n",
    "\n",
    "print(\"fitting models without FS now\")\n",
    "\n",
    "for model in models:\n",
    "    print(\"-------------------------------\")\n",
    "    print(f\"Starting fit for {model}\")\n",
    "    print(\"-------------------------------\")\n",
    "    start = time.time()\n",
    "    clf = clone(model)\n",
    "    clf.fit(transform_pipe[0].transform(X_train), y_train)\n",
    "    scores = custom_scorer(clf, transform_pipe[0].transform(X_test), y_test)\n",
    "    end = time.time()\n",
    "    scores['model'] = type(model).__name__\n",
    "    scores['n_features'] = X_train.shape[1]\n",
    "    scores['time'] = end - start\n",
    "    print(\"-------------------------------\")\n",
    "    print(f\"Results for {model} with GA selection: \")\n",
    "    print(scores)\n",
    "    print(f\"Took {end - start} seconds\")\n",
    "    print(\"-------------------------------\")\n",
    "    results['no_fs_scores'].append(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('ccd_results_blb_no_cv_binary.pickle', 'wb') as handle:\n",
    "    pickle.dump(results, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ccd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
