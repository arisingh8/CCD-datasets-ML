{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)\n",
      "/tmp/ipykernel_1550/4099036018.py:6: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "from sklearnex import patch_sklearn\n",
    "patch_sklearn()\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm.autonotebook import tqdm\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, clone\n",
    "\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as skLDA\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score\n",
    "from sklearn import set_config\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "import random\n",
    "from deap import base, creator, tools, algorithms\n",
    "\n",
    "import multiprocessing\n",
    "\n",
    "from cuml.svm import LinearSVC as cuSVC\n",
    "from cuml import LogisticRegression as cuLR\n",
    "from cuml.neighbors import KNeighborsClassifier as cuKNN\n",
    "from cuml.ensemble import RandomForestClassifier as cuRF\n",
    "from cuml.naive_bayes import GaussianNB as cuNB\n",
    "from sklearn.naive_bayes import GaussianNB as skNB\n",
    "from sklearn.ensemble import RandomForestClassifier as skRF\n",
    "from sklearn.neighbors import KNeighborsClassifier as skKNN\n",
    "from sklearn.svm import LinearSVC as skSVC\n",
    "from sklearn.linear_model import LogisticRegression as skLR\n",
    "\n",
    "import random\n",
    "import shap\n",
    "import time\n",
    "import functools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(\"data/BaIoT/danmini_combined.parquet\")\n",
    "X_data = StandardScaler().fit_transform(df.drop(['traffic_type'], axis=1))\n",
    "y_data = LabelEncoder().fit_transform(df['traffic_type'])\n",
    "del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_converged(series, w, eps):\n",
    "    if w >= len(series):\n",
    "        return False\n",
    "\n",
    "    current = series[len(series)-1]\n",
    "    window = series[-w-1:-1]\n",
    "    average_error = np.mean(np.abs(window-current)/np.abs(current))\n",
    "    return average_error <= eps\n",
    "\n",
    "def bag_of_little_bootstraps(X, y, clf, scorer, gamma, r_eps = 0.05, r_w = 20, s_eps = 0.05, s_w = 3):\n",
    "    n = len(X)\n",
    "    b = round(n**gamma)\n",
    "    print(b)\n",
    "    subset_scores = []\n",
    "    while not has_converged(subset_scores, s_w, s_eps):\n",
    "        subsample_idx = random.sample(range(n), k=b)\n",
    "        X_sampled = X[subsample_idx, :]\n",
    "        y_sampled = y[subsample_idx]\n",
    "        train, test = train_test_split(np.arange(b), test_size=0.33, stratify=y_sampled, random_state=42)\n",
    "        monte_carlo_scores = []\n",
    "        while not has_converged(monte_carlo_scores, r_w, r_eps):\n",
    "            sample_weights = np.random.multinomial(n=n, pvals=[1/b]*b, size=1)[0]\n",
    "            model = clone(clf)\n",
    "            model.fit(X=X_sampled[train, :], \n",
    "                    y=y_sampled[train], \n",
    "                    sample_weight=sample_weights[train])\n",
    "            monte_carlo_scores.append(\n",
    "                scorer(y_sampled[test], \n",
    "                       model.predict_proba(X_sampled[test, :]), \n",
    "                       sample_weight=sample_weights[test])\n",
    "            )\n",
    "        subset_scores.append(np.mean(monte_carlo_scores))\n",
    "    print(\"num subsets taken: \" + str(len(subset_scores)))\n",
    "    print(\"mean acc: \" + str(np.mean(subset_scores)))\n",
    "    return np.mean(subset_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8037\n",
      "num subsets taken: 6\n",
      "mean acc: 0.9920372276763697\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9920372276763697"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_of_little_bootstraps(X_data, y_data, skNB(), functools.partial(roc_auc_score, average=\"weighted\", multi_class=\"ovr\"), 0.65, r_eps = 0.05, r_w = 20, s_eps = 0.03, s_w = 5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ccd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
